name: Python CI for Ollama System Check

on:
  push:
    branches:
      - main  # Запускаем на push в main
  pull_request:
    branches:
      - main  # Запускаем на pull request в main

jobs:
  ollama-system-check:
    runs-on: ubuntu-latest  # Используем последнюю версию Ubuntu

    steps:
      # Шаг 1: Клонировать репозиторий
      - name: Checkout repository
        uses: actions/checkout@v2

      # Шаг 2: Установить Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      # Шаг 3: Установить зависимости
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Шаг 4: Установить и развернуть Ollama
      - name: Install Ollama model
        run: |
          # Устанавливаем Ollama
          curl -fsSL https://ollama.com/download -o ollama.tar.gz
          tar -xzvf ollama.tar.gz
          sudo mv ollama /usr/local/bin/ollama

      # Шаг 5: Проверка работы модели Ollama
      - name: Check if Ollama model is working
        run: |
          ollama pull gemma:2b  # Или любую другую модель, например, deepseek
          ollama generate --model gemma:2b --prompt "Hello, World!"  # Пример запроса

      # Шаг 6: Запуск твоего скрипта
      - name: Run main script
        run: |
          python app.py  # Замените на путь к своему скрипту
        continue-on-error: true  # Чтобы не останавливать workflow, если скрипт не прошел (можно использовать для отладки)
